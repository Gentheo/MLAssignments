% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Assignmentw4-TB},
  pdfauthor={Thomas-Trey-Barnes},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Assignmentw4-TB}
\author{Thomas-Trey-Barnes}
\date{7/15/2020}

\begin{document}
\maketitle

\hypertarget{background}{%
\section{Background}\label{background}}

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now
possible to collect a large amount of data about personal activity
relatively inexpensively. These type of devices are part of the
quantified self movement -- a group of enthusiasts who take measurements
about themselves regularly to improve their health, to find patterns in
their behavior, or because they are tech geeks. One thing that people
regularly do is quantify how much of a particular activity they do, but
they rarely quantify how well they do it. In this project, your goal
will be to use data from accelerometers on the belt, forearm, arm, and
dumbell of 6 participants. They were asked to perform barbell lifts
correctly and incorrectly in 5 different ways. More information is
available from the website here:
\url{http://groupware.les.inf.puc-rio.br/har} (see the section on the
Weight Lifting Exercise Dataset).

\hypertarget{data}{%
\subsection{Data}\label{data}}

The training data for this project are available here:

\url{https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv}

The test data are available here:

\url{https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv}

The data for this project come from this source:
\url{http://groupware.les.inf.puc-rio.br/har}. If you use the document
you create for this class for any purpose please cite them as they have
been very generous in allowing their data to be used for this kind of
assignment.

\hypertarget{step-1-load-data-and-libaries}{%
\subsection{Step-1: Load Data and
Libaries}\label{step-1-load-data-and-libaries}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'ggplot2' was built under R version 3.5.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lattice)}
\KeywordTok{library}\NormalTok{(knitr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'knitr' was built under R version 3.5.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(caret)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'caret' was built under R version 3.5.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Loading required package: lattice}
\CommentTok{## Loading required package: ggplot2}
\KeywordTok{library}\NormalTok{(rpart)}
\KeywordTok{library}\NormalTok{(rpart.plot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'rpart.plot' was built under R version 3.5.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(randomForest)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'randomForest' was built under R version 3.5.3
\end{verbatim}

\begin{verbatim}
## randomForest 4.6-14
\end{verbatim}

\begin{verbatim}
## Type rfNews() to see new features/changes/bug fixes.
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'randomForest'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:ggplot2':
## 
##     margin
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(rattle)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: tibble
\end{verbatim}

\begin{verbatim}
## Warning: package 'tibble' was built under R version 3.5.3
\end{verbatim}

\begin{verbatim}
## Loading required package: bitops
\end{verbatim}

\begin{verbatim}
## Rattle: A free graphical interface for data science with R.
## Version 5.4.0 Copyright (c) 2006-2020 Togaware Pty Ltd.
## Type 'rattle()' to shake, rattle, and roll your data.
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'rattle'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:randomForest':
## 
##     importance
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(RGtk2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'RGtk2' was built under R version 3.5.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(corrplot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'corrplot' was built under R version 3.5.3
\end{verbatim}

\begin{verbatim}
## corrplot 0.84 loaded
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## corrplot 0.84 loaded}
\CommentTok{# set the URL for the download}
\NormalTok{UrlTrain <-}\StringTok{ "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"}
\NormalTok{UrlTest  <-}\StringTok{ "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"}

\CommentTok{# download the datasets and perform initial clean in one step}
\NormalTok{training_data <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(UrlTrain, }\DataTypeTok{na.strings =} \KeywordTok{c}\NormalTok{(}\StringTok{"NA"}\NormalTok{, }\StringTok{"#DIV/0!"}\NormalTok{, }\StringTok{""}\NormalTok{))}
\NormalTok{test_data <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(UrlTest, }\DataTypeTok{na.strings =} \KeywordTok{c}\NormalTok{(}\StringTok{"NA"}\NormalTok{, }\StringTok{"#DIV/0!"}\NormalTok{, }\StringTok{""}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-preparation}{%
\subsection{Data Preparation}\label{data-preparation}}

We first remove data that contains more than 95\% of the observation to
be NA, these are filtered out.

We then verifying we have removed NA correctly

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colSums}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(clean_training_data))}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(clean_training_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    X            user_name raw_timestamp_part_1 
##                    0                    0                    0 
## raw_timestamp_part_2       cvtd_timestamp           new_window 
##                    0                    0                    0 
##           num_window            roll_belt           pitch_belt 
##                    0                    0                    0 
##             yaw_belt     total_accel_belt         gyros_belt_x 
##                    0                    0                    0 
##         gyros_belt_y         gyros_belt_z         accel_belt_x 
##                    0                    0                    0 
##         accel_belt_y         accel_belt_z        magnet_belt_x 
##                    0                    0                    0 
##        magnet_belt_y        magnet_belt_z             roll_arm 
##                    0                    0                    0 
##            pitch_arm              yaw_arm      total_accel_arm 
##                    0                    0                    0 
##          gyros_arm_x          gyros_arm_y          gyros_arm_z 
##                    0                    0                    0 
##          accel_arm_x          accel_arm_y          accel_arm_z 
##                    0                    0                    0 
##         magnet_arm_x         magnet_arm_y         magnet_arm_z 
##                    0                    0                    0 
##        roll_dumbbell       pitch_dumbbell         yaw_dumbbell 
##                    0                    0                    0 
## total_accel_dumbbell     gyros_dumbbell_x     gyros_dumbbell_y 
##                    0                    0                    0 
##     gyros_dumbbell_z     accel_dumbbell_x     accel_dumbbell_y 
##                    0                    0                    0 
##     accel_dumbbell_z    magnet_dumbbell_x    magnet_dumbbell_y 
##                    0                    0                    0 
##    magnet_dumbbell_z         roll_forearm        pitch_forearm 
##                    0                    0                    0 
##          yaw_forearm  total_accel_forearm      gyros_forearm_x 
##                    0                    0                    0 
##      gyros_forearm_y      gyros_forearm_z      accel_forearm_x 
##                    0                    0                    0 
##      accel_forearm_y      accel_forearm_z     magnet_forearm_x 
##                    0                    0                    0 
##     magnet_forearm_y     magnet_forearm_z               classe 
##                    0                    0                    0
\end{verbatim}

We also remove col1 to col7 because they are not relevent to the model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clean_training_data <-}\StringTok{ }\NormalTok{clean_training_data[,}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{)]}
\NormalTok{clean_test_data <-}\StringTok{ }\NormalTok{test_data[,}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

The training and test data is then partitioned into the training set and
cross validation set

Data is now ready to have algorithms applied

\hypertarget{machine-learning-algorithm---decision-tree}{%
\subsection{Machine Learning Algorithm - Decision
Tree}\label{machine-learning-algorithm---decision-tree}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{decisionTreeMod <-}\StringTok{ }\KeywordTok{train}\NormalTok{(classe }\OperatorTok{~}\NormalTok{., }\DataTypeTok{method=}\StringTok{'rpart'}\NormalTok{, }\DataTypeTok{data=}\NormalTok{training_training_data)}
\end{Highlighting}
\end{Shaded}

Predict with decision tree and display output and confusion matrix;
result model is not ideal due to low accuracy

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{decisionTreePrediction <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(decisionTreeMod, training_crossval_data)}
\KeywordTok{confusionMatrix}\NormalTok{(training_crossval_data}\OperatorTok{$}\NormalTok{classe, decisionTreePrediction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1254   29  109    0    3
##          B  397  339  213    0    0
##          C  382   23  450    0    0
##          D  364  147  293    0    0
##          E  127  125  238    0  411
## 
## Overall Statistics
##                                           
##                Accuracy : 0.5004          
##                  95% CI : (0.4863, 0.5145)
##     No Information Rate : 0.5147          
##     P-Value [Acc > NIR] : 0.978           
##                                           
##                   Kappa : 0.3474          
##                                           
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.4968  0.51131  0.34536       NA  0.99275
## Specificity            0.9408  0.85617  0.88753   0.8361  0.89087
## Pos Pred Value         0.8989  0.35722  0.52632       NA  0.45616
## Neg Pred Value         0.6381  0.91808  0.78933       NA  0.99925
## Prevalence             0.5147  0.13520  0.26570   0.0000  0.08442
## Detection Rate         0.2557  0.06913  0.09176   0.0000  0.08381
## Detection Prevalence   0.2845  0.19352  0.17435   0.1639  0.18373
## Balanced Accuracy      0.7188  0.68374  0.61644       NA  0.94181
\end{verbatim}

Plotting the decision tree for graphical display

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rpart.plot}\NormalTok{(decisionTreeMod}\OperatorTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Final-Method-submission_files/figure-latex/unnamed-chunk-8-1.pdf}

\hypertarget{machine-learning-algorithm---random-forest}{%
\subsection{Machine Learning Algorithm - Random
Forest}\label{machine-learning-algorithm---random-forest}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rfMod <-}\StringTok{ }\KeywordTok{train}\NormalTok{(classe }\OperatorTok{~}\NormalTok{., }\DataTypeTok{method=}\StringTok{'rf'}\NormalTok{, }\DataTypeTok{data=}\NormalTok{training_training_data, }\DataTypeTok{ntree=}\DecValTok{128}\NormalTok{)}
\NormalTok{rfPrediction <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(rfMod, training_crossval_data)}
\KeywordTok{confusionMatrix}\NormalTok{(training_crossval_data}\OperatorTok{$}\NormalTok{classe, rfPrediction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1395    0    0    0    0
##          B    7  940    2    0    0
##          C    0   10  836    9    0
##          D    0    0   20  784    0
##          E    0    0    0    6  895
## 
## Overall Statistics
##                                           
##                Accuracy : 0.989           
##                  95% CI : (0.9857, 0.9917)
##     No Information Rate : 0.2859          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9861          
##                                           
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9950   0.9895   0.9744   0.9812   1.0000
## Specificity            1.0000   0.9977   0.9953   0.9951   0.9985
## Pos Pred Value         1.0000   0.9905   0.9778   0.9751   0.9933
## Neg Pred Value         0.9980   0.9975   0.9946   0.9963   1.0000
## Prevalence             0.2859   0.1937   0.1750   0.1629   0.1825
## Detection Rate         0.2845   0.1917   0.1705   0.1599   0.1825
## Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837
## Balanced Accuracy      0.9975   0.9936   0.9848   0.9882   0.9993
\end{verbatim}

Random Forest generated a much more accurate model therefore predictions
are made using Random forest

\#Prediction

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(rfMod,clean_test_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
\end{verbatim}

\hypertarget{conculsion}{%
\subsection{Conculsion}\label{conculsion}}

Previously we observed that the random forest algorithm outperformed the
decision tree in relation to accuracy of the models. Random forest
generating an accuracy of 99.25\% vs.~the decision tree's accuracy at
\textless50\%. It is the analyst recommendation that the random forest
machine learning algorithm be used to make predictions of this
particular data set.

\end{document}
